searchState.loadedDescShard("opendal",0,"Apache OpenDAL\u2122 is a data access layer that allows users \u2026\naliyun_drive: Aliyun Drive services.\nalluxio: Alluxio services.\nThe given path already exists thus we failed to the \u2026\natomicserver: Atomicserver services.\nazblob: Azure Storage Blob services.\nAzdls: Azure Data Lake Storage Gen2.\nazfile: Azfile Services\nB2: Backblaze B2 Services.\nBlockingLister is designed to list entries at given path \u2026\nBlockingOperator is the entry for all public blocking APIs.\nBlockingReader is designed to read data from given path in \u2026\nBlockingWriter is designed to write data into given path \u2026\nBuffer is a wrapper of contiguous <code>Bytes</code> and non-contiguous \u2026\nBufferIterator is an iterator of buffers.\nBufferSink is the adapter of <code>futures::Sink</code> generated by \u2026\nBuilder is used to set up underlying services.\nAssociated builder for this configuration.\ncacache: cacache backend support.\nKey for cache control.\nCapability is used to describe what operations are \u2026\nChainsafe: Chainsafe Services.\ncloudflare-kv: Cloudflare KV services.\nCompfs: Compio fs Services.\nThe special metadata key that used to mark this entry \u2026\nThe condition of this operation is not match.\nAssociated configuration for this builder.\nThe config for backend is invalid.\nConfigurator is used to configure the underlying service.\nKey for content disposition.\nKey for content length.\nKey for content md5.\nKey for content range.\nKey for content type.\ncos: Tencent Cloud Object Storage services.\nCustom that allow users to implement services outside of \u2026\nd1: D1 services\nDIR means the path can be listed.\ndashmap: dashmap backend support.\ndbfs: DBFS backend support.\ndropbox: Dropbox services.\nEntry returned by <code>Lister</code> or <code>BlockingLister</code> to represent a \u2026\nEntryMode represents the mode.\nContains the error value\nError is the error struct returned by all opendal \u2026\nErrorKind is all kinds of Error of opendal.\nKey for etag.\netcd: Etcd Services\nExecute trait is used to execute task in background.\nExecutor that runs futures in background.\nFILE means the path has data to read.\nfoundationdb: Foundationdb services.\nfs: POSIX-like file system.\nftp: FTP backend.\nFuturesAsyncReader is the adapter of <code>AsyncRead</code>, \u2026\nFuturesIoAsyncWriter is the adapter of <code>AsyncWrite</code> for \u2026\nFuturesBytesSink is the adapter of <code>futures::Sink</code> generated \u2026\nFuturesBytesStream is the adapter of <code>Stream</code> generated by \u2026\ngcs: Google Cloud Storage backend.\ngdrive: GoogleDrive services.\nghac: GitHub Action Cache services.\nGithub Contents: Github contents support.\ngridfs: MongoDB Gridfs Services\nhdfs: Hadoop Distributed File System.\nNative HDFS: Hdfs Native service, using rust hdfs-native \u2026\nhttp: HTTP backend.\nhuggingface: Huggingface services.\nicloud: APPLE icloud services.\nipmfs: IPFS HTTP Gateway\nipmfs: IPFS mutable file system\nThe given path is a directory.\nThe given file paths are same.\nKoofr: Koofr Services.\nKey for last modified.\nlibsql: Libsql services\nLister is designed to list entries at given path in an \u2026\nmemcached: Memcached service support.\nmemory: In memory backend support.\nMetadata carries all metadata associated with a path.\nMetakey describes the metadata keys that can be stored or \u2026\nmini-moka: Mini Moka backend support.\nKey for mode.\nmoka: moka backend support.\nmongodb: MongoDB Services\nmonoiofs: monoio fs services.\nmysql: Mysql services\nThe given path is not a directory.\nThe given path is not found.\nobs: Huawei Cloud OBS services.\nContains the success value\nonedrive: Microsoft OneDrive services.\nOperator is the entry for all public async APIs.\nOperatorBuilder is a typed builder to build an Operator.\nMetadata for operator, users can use this metadata to get \u2026\noss: Aliyun Object Storage Services\nPcloud: Pcloud Services.\nThe given path doesn\u2019t have enough permission for this \u2026\npersy: persy backend support.\npostgresql: Postgresql services\nThe range of the content is not satisfied.\nRequests that sent to this path is over the limit, please \u2026\nReader is designed to read data from given path in an \u2026\nredb: Redb Services\nredis: Redis services\nResult that is a wrapper of <code>Result&lt;T, opendal::Error&gt;</code>\nrocksdb: RocksDB services\ns3: AWS S3 alike services.\nAssociated scheme for this builder. It indicates what \u2026\nServices that OpenDAL supports\nSeafile: Seafile Services.\nsftp: SFTP services\nsled: Sled services\nsqlite: Sqlite services\nStdIterator is the adapter of <code>Iterator</code> for <code>BlockingReader</code>.\nStdReader is the adapter of <code>Read</code>, <code>Seek</code> and <code>BufRead</code> for \u2026\nStdWriter is the adapter of <code>std::io::Write</code> for \u2026\nSupabase: Supabase storage service\nsurrealdb: Surrealdb Services\nswift: Swift backend support.\ntikv: Tikv Services\nOpenDAL don\u2019t know what happened here, and no actions \u2026\nUnknown means we don\u2019t know what we can do on this path.\nUnderlying service doesn\u2019t support this operation.\nUpyun: Upyun Services.\nKey for user metadata\nVercel Artifacts: Vercel Artifacts service, as known as \u2026\nVercelBlob: VercelBlob Services.\nKey for version.\nwebdav: WebDAV support.\nwebhdfs: WebHDFS RESTful API Services\nWriter is designed to write data into given path in an \u2026\nYandexDisk: YandexDisk Services.\nAbort the writer and clean up all written data.\nIf operator supports batch.\nIf operator supports batch delete.\nThe max operations that operator supports in batch.\nCreate a new blocking operator.\nIf operator supports blocking.\nConsume the accessor builder to build a service.\nCache control of this entry. Cache-Control is defined by \u2026\nCheck if this operator can work correctly.\nClose the writer and make sure all data have been \u2026\nClose the writer and make sure all data have been \u2026\nClose the internal writer and make sure all data have been \u2026\nContent-Disposition of this entry\nContent length of this entry.\nContent MD5 of this entry.\nContent Range of this entry.\nContent Type of this entry.\nCopy a file from <code>from</code> to <code>to</code>.\nCopy a file from <code>from</code> to <code>to</code>.\nIf operator supports copy.\nNumber of <code>Bytes</code> in <code>Buffer</code>.\nCreate a dir at given path.\nCreate a dir at given path.\nIf operator supports create dir.\nGet current <code>Bytes</code>.\nGet the default executor.\nDelete the given path.\nDelete given path.\nIf operator supports delete.\nDelete the given path with extra options.\nDelete given path with options.\nThis module holds documentation for OpenDAL.\nGet all enabled schemes.\nETag of this entry.\nExecute async task in background.\nexecutors module provides implementations for the <code>Execute</code> \u2026\nFetch specific ranges from reader.\nFinish the building to construct an Operator.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nCreate a new operator from given config.\nDeserialize from an iterator.\nDeserialize from an iterator.\nCreate a new operator from given iterator in static \u2026\nCreate a new operator from given map.\nGet [<code>Full Capability</code>] of operator.\nGet information of underlying accessor.\nGet information of underlying accessor.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nConvert this configuration into a service builder.\nConvert reader into <code>StdBytesIterator</code> which implements \u2026\nConvert writer into <code>FuturesBytesSink</code> which implements \u2026\nConvert reader into <code>FuturesBytesStream</code> which implements \u2026\nConvert reader into <code>FuturesAsyncReader</code> which implements \u2026\nConvert writer into <code>FuturesAsyncWriter</code> which implements \u2026\nConsume this entry to get it\u2019s path and metadata.\nConvert self into static str.\nConvert self into static str.\nConvert reader into <code>StdReader</code> which implements \u2026\nConvert writer into <code>StdWriter</code> which implements \u2026\nCheck if this mode is DIR.\nReturns <code>true</code> if this metadata is for a directory.\nCheck if buffer is empty.\nCheck if this path exists or not.\nCheck if this path exists or not.\nCheck if this mode is FILE.\nReturns <code>true</code> if this metadata is for a file.\nCheck if this error is temporary.\nReturn error\u2019s kind.\nLast modified of this entry.\nCreate a new layer with static dispatch.\nCreate a new layer with dynamic dispatch.\n<code>Layer</code> is the mechanism to intercept operations.\nGet the length of the buffer.\nGet current operator\u2019s limit. Limit is usually the \u2026\nGet current operator\u2019s limit\nList entries that starts with given <code>path</code> in parent dir.\nList entries that starts with given <code>path</code> in parent dir.\nIf operator supports list.\nList entries that starts with given <code>path</code> in parent dir \u2026\nList entries that starts with given <code>path</code> in parent dir. \u2026\nIf backend supports list with limit.\nIf backend supports list with recursive.\nIf backend supports list with start after.\nList entries that starts with given <code>path</code> in parent dir.\nList entries that starts with given <code>path</code> in parent dir.\nList entries that starts with given <code>path</code> in parent dir \u2026\nList entries within a given directory as an iterator with \u2026\nOperate on error with map.\nFetch metadata of this entry.\nGet the metakey from metadata.\nmode represent this entry\u2019s mode.\nName of entry. Name is the last segment of path.\nName of backend, could be empty if underlying backend doesn\u2026\nGet [<code>Native Capability</code>] of operator.\nCreate a new buffer iterator.\nCreate a new operator builder.\nCreate a new Error with error kind and message.\nCreate a new empty buffer.\nCreate a new metadata\nCreate a default executor.\nCreate a new operator with input builder.\nFunctions provides the functions generated by \u2026\nFutures provides the futures generated by <code>Operator</code>\nPath of entry. Path is relative to operator\u2019s root.\nIf operator supports presign.\nPresign an operation for read.\nIf operator supports presign read.\nPresign an operation for read with extra options.\nPresign an operation for stat(head).\nIf operator supports presign stat.\nPresign an operation for stat(head).\nPresign an operation for write.\nIf operator supports presign write.\nPresign an operation for write with extra options.\nRaw modules provide raw APIs that used by underlying \u2026\nRead give range from reader into <code>Buffer</code>.\nRead give range from reader into <code>Buffer</code>.\nRead the whole path into a bytes.\nRead the whole path into a bytes.\nIf operator supports read.\nRead all data from reader into given <code>BufMut</code>.\nThis operation will copy and write bytes into given <code>BufMut</code>\u2026\nRead the whole path into a bytes with extra options.\nRead the whole path into a bytes with extra options.\nIf operator supports read with if match.\nIf operator supports read with if none match.\nif operator supports read with override cache control.\nif operator supports read with override content \u2026\nif operator supports read with override content type.\nCreate a new reader which can read the whole path.\nCreate a new reader which can read the whole path.\nCreate a new reader with extra options\nCreate a new reader with extra options\nNotes\nNotes\nRemove the path and all nested dirs and files recursively.\nRemove the path and all nested dirs and files recursively.\nremove will remove files via the given paths.\nremove will remove files via the given paths.\nRename a file from <code>from</code> to <code>to</code>.\nRename a file from <code>from</code> to <code>to</code>.\nIf operator supports rename.\nRoot of operator, will be in format like <code>/path/to/dir/</code>\n<code>Scheme</code> of operator.\nServices will provide builders to build underlying \u2026\nSet cache control of this entry.\nSet Content-Disposition of this entry\nSet content length of this entry.\nSet content MD5 of this entry.\nSet Content Range of this entry.\nSet Content Type of this entry.\nSet ETag of this entry.\nSet Last modified of this entry.\nSet mode for entry.\nSet permanent status for error.\nSet persistent status for error.\nSet source for error.\nSet temporary status for error.\nSet version of this entry.\nReturns a slice of self for the provided range.\nGet given path\u2019s metadata.\nGet given path\u2019s metadata.\nIf operator supports stat.\nGet given path\u2019s metadata with extra options.\nGet given path\u2019s metadata with extra options.\nIf operator supports stat with if match.\nIf operator supports stat with if none match.\nif operator supports read with override cache control.\nif operator supports read with override content \u2026\nif operator supports read with override content type.\nReturn a future that will be resolved after the given \u2026\nReturn a future that will be resolved after the given \u2026\nCombine all bytes together into one single <code>Bytes</code>.\nConvert buffer into a slice of <code>IoSlice</code> for vectored write.\nCombine all bytes together into one single <code>Vec&lt;u8&gt;</code>.\nShortens the buffer, keeping the first <code>len</code> bytes and \u2026\nUser defined metadata of this entry\nVersion of this entry.\nCreate a new operator via given scheme and iterator of \u2026\nCreate a new operator from given scheme and map.\nCreate a new executor with given execute impl.\nSet cache control of this entry.\nSet Content-Disposition of this entry\nSet content length of this entry.\nSet content MD5 of this entry.\nSet Content Range of this entry.\nSet Content Type of this entry.\nAdd more context in error.\nSpecify the default executor.\nSet ETag of this entry.\nSet Last modified of this entry.\nSpecify the batch limit.\nSpecify the batch limit.\nSet mode for entry.\nUpdate error\u2019s operation.\nSet user defined metadata of this entry\nSet version of this entry.\nWrite <code>Buffer</code> into writer.\nWrite <code>Buffer</code> into writer.\nWrite bytes into path.\nWrite bytes into given path.\nIf operator supports write.\nIf operator supports write by append.\nIf operator supports write with empty content.\nIf operator supports write can be called in multi times.\nWrite <code>bytes::Buf</code> into inner writer.\nwrite_multi_align_size is the align size that services \u2026\nwrite_multi_max_size is the max size that services support \u2026\nwrite_multi_min_size is the min size that services support \u2026\nwrite_total_max_size is the max size that services support \u2026\nWrite data with extra options.\nWrite data with option described in OpenDAL RFC-0661\nIf operator supports write with cache control.\nIf operator supports write with content disposition.\nIf operator supports write with content type.\nIf operator supports write with user defined metadata\nWrite multiple bytes into path.\nWrite multiple bytes into given path.\nWrite multiple bytes into path with extra options.\nCreate a new reader with extra options\nChanges log for all OpenDAL released versions.\nCompare opendal with other projects to find out the \u2026\nThe core concepts of OpenDAL\u2019s public API.\nThe internal implement details of OpenDAL.\nRFCs - OpenDAL Active RFC List\nUpgrade and migrate procedures while OpenDAL meets \u2026\nOpenDAL vs object_store\nThe internal implementation details of <code>Access</code>.\nThe internal implementation details of <code>Layer</code>.\nRFC example\nObject native API\nError handle\nAuto region\nObject stream\nLimited reader\nPath normalization\nAsync streaming IO\nRemove credential\nCreate dir\nRetryable error\nObject ID\nDir entry\nAccessor capabilities\nPresign\nCommand line interface\nInit from iter\nMultipart\nGateway\nNew builder\nWrite refactor\nList metadata reuse\nBlocking API\nRedis service\nSplit capabilities\nPath in accessor\nGeneric KV services\nObject reader\nRefactor error\nObject handler\nObject metadataer\nQuery based metadata\nObject writer\nRemove object concept\nOperation extension\nWriter sink API\nAppend API\nChain based operator API\nObject versioning\nMerge append into write\nLister API\nList with metakey\nNative capability\nRemove write copy from\nConfig\nAlign list API\nList prefix\nLazy reader\nList recursive\nConcurrent stat in list\nBuffered Reader\nConcurrent Writer\nDeleter API\nRange Based Read API\nExecutor API\nExecutor that uses the <code>tokio::task::spawn</code> to execute \u2026\nTokio\u2019s JoinHandle has it\u2019s own <code>abort</code> support, so \u2026\nReturns the argument unchanged.\nCalls <code>U::from(self)</code>.\nAdd Efficient, logical \u2018stack\u2019 traces of async \u2026\nAdd a Instrument await-tree for actor-based applications \u2026\nAdd blocking API support for non-blocking services.\nInject chaos into underlying services for robustness test.\nAdd concurrent request limit.\nSupport User Statically-Defined Tracing(aka USDT) on Linux\nAdd fastrace for every operation.\nAdd an immutable in-memory index for underlying storage \u2026\nLoggingInterceptor is used to intercept the log.\nAdd log for every operation.\nAdd metrics for every operation.\nA layer that can automatically set <code>Content-Type</code> based on \u2026\nAdd opentelemetry::trace for every operation.\nAdd prometheus-client for every operation.\nAdd prometheus for every operation.\nRetryInterceptor is used to intercept while retry happened.\nAdd retry for temporary failed operations.\nAdd a bandwidth rate limiter to the underlying services.\nAdd timeout for every operation to avoid slow or \u2026\nAdd tracing for every operation.\nset buckets for bytes_total\nCreate a new <code>BlockingLayer</code> with the current runtime\u2019s \u2026\nset path label level 0: no path label, the path label will \u2026\nInsert keys from iter.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nInsert a key into index.\nEverytime RetryLayer is retrying, this function will be \u2026\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nEverytime there is a log, this function will be called.\nCreate a new retry layer.\nCreate a new ConcurrentLimitLayer will specify permits\nCreate the layer with specific logging interceptor.\nCreate a new <code>TimeoutLayer</code> with default settings.\nCreate a new chaos layer with specified error ratio.\nCreate PrometheusClientLayer while registering itself to \u2026\nCreate a new <code>ThrottleLayer</code> with given bandwidth and burst.\nCreate a new <code>AwaitTreeLayer</code>.\nset buckets for requests_duration_seconds\nSet factor of current backoff.\nSet io timeout for TimeoutLayer with given value.\nSet jitter of current backoff.\nSet max_delay of current backoff.\nSet max_times of current backoff.\nSet min_delay of current backoff.\nSet the retry interceptor as new notify.\ncreate PrometheusLayer by incoming registry.\nSet speed for TimeoutLayer with given value.\nSet timeout for TimeoutLayer with given value.\nFunction that generated by <code>BlockingOperator::delete_with</code>.\nFunction that generated by <code>BlockingOperator::list_with</code>.\nFunction that generated by <code>BlockingOperator::lister_with</code>.\nFunction that generated by <code>BlockingOperator::read_with</code>.\nFunction that generated by <code>BlockingOperator::reader_with</code>.\nFunction that generated by <code>BlockingOperator::stat_with</code>.\nFunction that generated by <code>BlockingOperator::write_with</code>.\nFunction that generated by <code>BlockingOperator::writer_with</code>.\nSet the append mode of op.\nSet the append mode of op.\nSet the chunk size of op.\nSet the content type of option\nSet the content type of option\nCall the function to consume all the input and generate a \u2026\nCall the function to consume all the input and generate a \u2026\nCall the function to consume all the input and generate a \u2026\nCall the function to consume all the input and generate a \u2026\nCall the function to consume all the input and generate a \u2026\nCall the function to consume all the input and generate a \u2026\nCall the function to consume all the input and generate a \u2026\nCall the function to consume all the input and generate a \u2026\nSet the chunk size of op.\nSet the chunk size of op.\nSet the content disposition of option\nSet the content disposition of option\nSet the content type of option\nSet the content type of option\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nSet the If-Match for this operation.\nSet the If-Match for this operation.\nSet the If-None-Match for this operation.\nSet the If-None-Match for this operation.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nThe limit passed to underlying service to specify the max \u2026\nThe limit passed to underlying service to specify the max \u2026\nMetakey is used to control which meta should be returned.\nMetakey is used to control which meta should be returned.\nSets the cache-control header that should be send back by \u2026\nSets the content-disposition header that should be send \u2026\nSets the content-type header that should be send back by \u2026\nSet the range for this operation.\nThe recursive is used to control whether the list \u2026\nThe recursive is used to control whether the list \u2026\nThe start_after passes to underlying service to specify \u2026\nThe start_after passes to underlying service to specify \u2026\nSet the version for this operation.\nSet the version for this operation.\nSet the version for this operation.\nFuture that generated by <code>Operator::delete_with</code>.\nFuture that generated by <code>Operator::list_with</code> or \u2026\nFuture that generated by <code>Operator::list_with</code> or \u2026\nFuture that generated by <code>Operator::presign_read_with</code>.\nFuture that generated by <code>Operator::presign_stat_with</code>.\nFuture that generated by <code>Operator::presign_write_with</code>.\nFuture that generated by <code>Operator::read_with</code> or \u2026\nFuture that generated by <code>Operator::read_with</code> or \u2026\nFuture that generated by <code>Operator::stat_with</code>.\nFuture that generated by <code>Operator::write_with</code>.\nFuture that generated by <code>Operator::writer_with</code>.\nOperatorFuture is the future generated by <code>Operator</code>.\nSet the append mode of op.\nSet the append mode of op.\nSet the append mode of op.\nSet the append mode of op.\nSet the content type of option\nSet the content type of option\nSet the content type of option\nSet the content type of option\nSet the content type of option\nSet the content type of option\nSet the chunk size for this reader.\nSet the chunk size for this operation.\nSet the buffer size of op.\nSet the chunk size of op.\nSet the chunk size for this operation.\nSet the chunk size for this reader.\nSet the buffer size of op.\nSet the chunk size of op.\nSet the concurrent read task amount.\nSet the concurrent read task amount.\nSet the maximum concurrent write task amount.\nConcurrent is used to control the number of concurrent \u2026\nConcurrent is used to control the number of concurrent \u2026\nSet the maximum concurrent write task amount.\nSet the concurrent read task amount.\nSet the concurrent read task amount.\nSet the maximum concurrent write task amount.\nSet the maximum concurrent write task amount.\nConcurrent is used to control the number of concurrent \u2026\nConcurrent is used to control the number of concurrent \u2026\nSet the content disposition of option\nSet the content disposition of option\nSet the content disposition of option\nSet the content disposition of option\nSet the content disposition of option\nSet the content disposition of option\nSet the content type of option\nSet the content type of option\nSet the content type of option\nSet the content type of option\nSet the content type of option\nSet the content type of option\nSet the executor for this operation.\nSet the executor for this operation.\nSet the executor for this operation.\nSet the executor for this operation.\nSet the executor for this operation.\nSet the executor for this operation.\nReturns the argument unchanged.\nSet the gap size for this reader.\nSet the gap size for this reader.\nSet the If-Match of the option\nSet the If-Match for this operation.\nSet the If-Match of the option\nSet the If-Match for this operation.\nSet the If-Match for this operation.\nSet the If-Match of the option\nSet the If-Match of the option\nSet the If-Match for this operation.\nSet the If-None-Match for this operation.\nSet the If-None-Match of the option\nSet the If-None-Match for this operation.\nSet the If-None-Match of the option\nSet the If-None-Match for this operation.\nSet the If-None-Match of the option\nSet the If-None-Match of the option\nSet the If-None-Match for this operation.\nCalls <code>U::from(self)</code>.\nThe limit passed to underlying service to specify the max \u2026\nThe limit passed to underlying service to specify the max \u2026\nThe limit passed to underlying service to specify the max \u2026\nThe limit passed to underlying service to specify the max \u2026\nMetakey is used to control which meta should be returned.\nMetakey is used to control which meta should be returned.\nMetakey is used to control which meta should be returned.\nMetakey is used to control which meta should be returned.\nSets the cache-control header that should be sent back by \u2026\nSets the cache-control header that should be sent back by \u2026\nSets the cache-control header that should be sent back by \u2026\nSets the cache-control header that should be sent back by \u2026\nSets the content-disposition header that should be sent \u2026\nSets the content-disposition header that should be sent \u2026\nSets the content-disposition header that should be sent \u2026\nSets the content-disposition header that should be sent \u2026\nSets the content-type header that should be sent back by \u2026\nSets the content-type header that should be sent back by \u2026\nSets the content-type header that should be sent back by \u2026\nSets the content-type header that should be sent back by \u2026\nSet the range header for this operation.\nSet the range header for this operation.\nThe recursive is used to control whether the list \u2026\nThe recursive is used to control whether the list \u2026\nThe recursive is used to control whether the list \u2026\nThe recursive is used to control whether the list \u2026\nThe start_after passes to underlying service to specify \u2026\nThe start_after passes to underlying service to specify \u2026\nThe start_after passes to underlying service to specify \u2026\nThe start_after passes to underlying service to specify \u2026\nSet the user defined metadata of the op\nSet the user defined metadata of the op\nSet the user defined metadata of the op\nSet the user defined metadata of the op\nSet the version for this operation.\nSet the version for this operation.\nSet the version for this operation.\nChange the version of this delete operation.\nSet the version for this operation.\nSet the version for this operation.\nSet the version for this operation.\nChange the version of this delete operation.\nUnderlying trait of all backends for implementers.\n<code>AccessDyn</code> is the dyn version of <code>Access</code> make it possible to \u2026\nAccessor is the type erased accessor with <code>Arc&lt;dyn Accessor&gt;</code>\u2026\nMetadata for accessor, users can use this metadata to get \u2026\nAtomicContentLength is a wrapper of AtomicU64 that used to \u2026\nOperation for <code>crate::raw::Access::batch</code>\nBatch operation used for batch.\nBatch results of <code>batch</code> operations.\nOperation for <code>crate::raw::Access::blocking_copy</code>\nOperation for <code>crate::raw::Access::blocking_create_dir</code>\nOperation for <code>crate::raw::Access::blocking_delete</code>\nOperation for <code>crate::raw::Access::blocking_list</code>\nBlockingLister is the associated lister returned \u2026\nOperation for <code>crate::raw::oio::BlockingList::next</code>\nOperation for <code>crate::raw::Access::blocking_read</code>\nBlockingReader is the associated reader returned \u2026\nOperation for <code>crate::raw::oio::BlockingRead::read</code>\nOperation for <code>crate::raw::Access::blocking_rename</code>\nOperation for <code>crate::raw::Access::blocking_stat</code>\nOperation for <code>crate::raw::Access::blocking_write</code>\nBlockingWriter is the associated writer returned \u2026\nOperation for <code>crate::raw::oio::BlockingWrite::close</code>\nOperation for <code>crate::raw::oio::BlockingWrite::write</code>\nBoxedFuture is the type alias of <code>futures::future::BoxFuture</code>\u2026\nBoxedStaticFuture is the type alias of \u2026\nBytesContentRange is the content range of bytes.\nBytesRange(offset, size) carries a range of content.\nConcurrentFutures is a stream that can hold a stream of \u2026\nConcurrentTasks is used to execute tasks concurrently.\nConfigDeserializer is used to deserialize given configs \u2026\nOperation for <code>crate::raw::Access::copy</code>\nOperation for <code>crate::raw::Access::create_dir</code>\nresults of <code>delete batch</code> operation\nOperation for <code>crate::raw::Access::delete</code>\nBatch delete operation.\nFormDataPart is a builder for multipart/form-data part.\nThe fourth type for the <code>FourWays</code>.\nFourWays is used to implement traits that based on four \u2026\nHttpBody is the streaming body that opendal\u2019s HttpClient \u2026\nHttpClient that used across opendal.\nOperation for <code>crate::raw::Access::info</code>\nLayer is used to intercept the operations on the \u2026\nLayeredAccess is layered accessor that forward all not \u2026\nThe layered accessor that returned by this layer.\nOperation for <code>crate::raw::Access::list</code>\nLister is the associated lister returned in <code>list</code> operation.\nOperation for <code>crate::raw::oio::List::next</code>\nMaybeSend is a marker to determine whether a type is <code>Send</code> \u2026\nMixedPart is a builder for multipart/mixed part.\nMultipart is a builder for multipart/form-data.\nThe first type for the <code>TwoWays</code>.\nThe first type for the <code>ThreeWays</code>.\nThe first type for the <code>FourWays</code>.\nArgs for <code>batch</code> operation.\nArgs for <code>copy</code> operation.\nArgs for <code>create</code> operation.\nArgs for <code>delete</code> operation.\nArgs for <code>list</code> operation.\nArgs for <code>presign</code> operation.\nArgs for <code>read</code> operation.\nArgs for reader operation.\nArgs for <code>rename</code> operation.\nArgs for <code>stat</code> operation.\nArgs for <code>write</code> operation.\nArgs for <code>writer</code> operation.\nOperation is the name for APIs in <code>Accessor</code>.\nPart is a trait for multipart part.\nPathCacher is a cache for path query.\nThe trait required for path cacher.\nOperation for <code>crate::raw::Access::presign</code>\nPresign operation used for presign.\nPresignedRequest is a presigned request return by <code>presign</code>.\nOperation for <code>crate::raw::Access::read</code>\nPresign a read operation.\nReader is the associated reader returned in <code>read</code> operation.\nOperation for <code>crate::raw::oio::Read::read</code>\nOperation for <code>crate::raw::Access::rename</code>\nReply for <code>batch</code> operation.\nReply for <code>copy</code> operation.\nReply for <code>create_dir</code> operation\nReply for <code>delete</code> operation\nReply for <code>list</code> operation.\nReply for <code>presign</code> operation.\nReply for <code>read</code> operation.\nReply for <code>rename</code> operation.\nReply for <code>stat</code> operation.\nReply for <code>write</code> operation.\nOperation for <code>crate::raw::Access::stat</code>\nPresign a stat(head) operation.\nTYPE is the type of multipart.\nThe third type for the <code>ThreeWays</code>.\nThe third type for the <code>FourWays</code>.\nThreeWays is used to implement traits that based on three \u2026\nThe second type for the <code>TwoWays</code>.\nThe second type for the <code>ThreeWays</code>.\nThe second type for the <code>FourWays</code>.\nTwoWays is used to implement traits that based on two ways.\nVERSION is the compiled version of OpenDAL.\nOperation for <code>crate::raw::Access::write</code>\nPresign a write operation.\nWriter is the associated writer returned in <code>write</code> \u2026\nOperation for <code>crate::raw::oio::Write::abort</code>\nOperation for <code>crate::raw::oio::Write::close</code>\nOperation for <code>crate::raw::oio::Write::write</code>\nProviding adapters and its implementations.\nAdvance the range by <code>n</code> bytes.\nGet the append from op.\nConsume the input and generate a request with multipart \u2026\nInvoke the <code>batch</code> operations.\nInvoke the <code>batch</code> operations.\nDyn version of <code>Accessor::batch</code>\nInvoke the <code>blocking_copy</code> operation on the specified <code>from</code> \u2026\nInvoke the <code>blocking_copy</code> operation on the specified <code>from</code> \u2026\nDyn version of <code>Accessor::blocking_copy</code>\nInvoke the <code>blocking_create</code> operation on the specified path.\nInvoke the <code>blocking_create</code> operation on the specified path.\nDyn version of <code>Accessor::blocking_create_dir</code>\nInvoke the <code>blocking_delete</code> operation on the specified path.\nInvoke the <code>blocking_delete</code> operation on the specified path.\nDyn version of <code>Accessor::blocking_delete</code>\nInvoke the <code>blocking_list</code> operation on the specified path.\nInvoke the <code>blocking_list</code> operation on the specified path.\nDyn version of <code>Accessor::blocking_list</code>\nInvoke the <code>blocking_read</code> operation on the specified path.\nInvoke the <code>blocking_read</code> operation on the specified path.\nDyn version of <code>Accessor::blocking_read</code>\nInvoke the <code>blocking_rename</code> operation on the specified <code>from</code> \u2026\nInvoke the <code>blocking_rename</code> operation on the specified <code>from</code> \u2026\nDyn version of <code>Accessor::blocking_rename</code>\nInvoke the <code>blocking_stat</code> operation on the specified path.\nInvoke the <code>blocking_stat</code> operation on the specified path.\nDyn version of <code>Accessor::blocking_stat</code>\nInvoke the <code>blocking_write</code> operation on the specified path.\nInvoke the <code>blocking_write</code> operation on the specified path.\nDyn version of <code>Accessor::blocking_write</code>\nBuild a new http client in async context.\nbuild_abs_path will build an absolute path with root.\nBuild header value from given string.\nbuild_rel_path will build a relative path towards root.\nbuild_rooted_abs_path will build an absolute path with \u2026\nGet the cache control from option\nGet chunk from option\nGet the chunk from op.\nClear all tasks and results.\nDrop all tasks.\nGet the async client from http client.\nGet the concurrent of list operation.\nGet concurrent from option\nGet the concurrent.\nSet the content for this part.\nSet the content for this part.\nGet the content disposition from option\nGet the content type from option\nInvoke the <code>copy</code> operation on the specified <code>from</code> path and <code>to</code>\u2026\nInvoke the <code>copy</code> operation on the specified <code>from</code> path and <code>to</code>\u2026\nDyn version of <code>Accessor::copy</code>\nCreate a dir by parent_id and name.\nInvoke the <code>create</code> operation on the specified path\nInvoke the <code>create</code> operation on the specified path\nDyn version of <code>Accessor::create_dir</code>\nInvoke the <code>delete</code> operation on the specified path.\nInvoke the <code>delete</code> operation on the specified path.\nDyn version of <code>Accessor::delete</code>\nEnsure input dir exists.\nExecute the task with given input.\nGet executor from option\nGet the executor from option\nGet expire from op.\nFetch a request in async way.\nformat will generates the bytes.\nformat authorization header by basic auth.\nformat authorization header by bearer token.\nformat content md5 header by given input.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nBuild a mixed part from a request.\nGet service\u2019s full capabilities.\nGet service\u2019s full capabilities.\nGet gap from option\nGet the id for the given path.\nGet basename from path.\nGet parent from path.\nCheck if there are remaining space to push new tasks.\nReturn true if there is remaining space to push new \u2026\nChunk if there are remaining results to fetch.\nInsert a header into part.\nInsert a header into part.\nReturn request\u2019s header.\nGet If-Match from option\nGet If-Match from option\nGet If-None-Match from option\nGet If-None-Match from option\nInvoke the <code>info</code> operation to get metadata of accessor.\nDyn version of <code>Accessor::info</code>\nInsert a new cache entry.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nConsume RpStat to get the inner metadata.\nConsume OpBatch into BatchOperation\nConsume OpPresign into (Duration, PresignOperation)\nInto parts.\nConsume reply to build a presigned request.\nConsume a mixed part to build a response.\nConsume RpBatch to get the batched results.\nConvert self into static str.\nReturn true if there is no futures in the queue.\nCheck if this range is full of this content.\nCheck if given operation is oneshot or not.\nIntercept the operations on the underlying storage.\nReturn the length of current concurrent futures (both \u2026\nGet the length that specified by this BytesContentRange, \u2026\nGet the limit of list operation.\nInvoke the <code>list</code> operation on the specified path.\nInvoke the <code>list</code> operation on the specified path.\nDyn version of <code>Accessor::list</code>\nLoad content length from AtomicU64.\nOperate on inner metadata.\nGet the current metakey.\nSet the method for request in this part.\nReturn request\u2019s method.\nName of backend, could be empty if underlying backend doesn\u2026\nGet backend\u2019s native capabilities.\nCreate a new path cacher.\nCreate a new RpBatch.\nCreate a new <code>HttpBody</code> with given stream and optional size.\nCreate a new part builder\nCreate a new mixed part with given uri.\nCreate a new config deserializer.\nCreate a new concurrent tasks with given executor, \u2026\nCreate a new ConcurrentFutures by specifying the number of \u2026\nCreate a new reply for <code>presign</code>.\nCreate a new PresignedRequest\nCreate a new reply for <code>read</code>.\nCreate a new reply for <code>stat</code>.\nCreate a new reply for <code>write</code>.\nCreate a new reply for <code>copy</code>.\nCreate a new reply for <code>rename</code>.\nCreate a new <code>OpCreateDir</code>.\nCreate a new <code>OpDelete</code>.\nCreate a new <code>OpList</code>.\nCreate a new <code>OpPresign</code>.\nCreate a new batch options.\nCreate a default <code>OpRead</code> which will read whole content of \u2026\nCreate a new <code>OpReader</code>.\nCreate a new <code>OpStat</code>.\nCreate a new <code>OpWrite</code>.\nCreate a new <code>OpWriter</code>.\nCreate a new <code>OpCopy</code>.\nCreate a new <code>OpMove</code>.\nCreate a new http client in async context.\nCreate a new <code>BytesRange</code>\nCreate a new multipart with random boundary.\nCreate a new AtomicContentLength.\nParse json deserialize error into opendal::Error.\nParse json serialize error into opendal::Error.\nCreate a new error happened during building request.\nCreate a new error happened during signing request.\nCreate a new error happened during signing request.\nParse std io error into opendal::Error.\nParse tokio error into opendal::Error.\nParse xml deserialize error into opendal::Error.\nFetch the successful result from the result queue.\nMake sure all operation are constructed by normalized path:\nMake sure root is normalized to style like <code>/abc/def/</code>.\nGet offset of BytesRange.\n<code>oio</code> provides OpenDAL\u2019s raw traits and types that opendal \u2026\nGet operation from op.\nGet operation from op.\nReturn the operation of this batch.\nReturns the cache-control header that should be send back \u2026\nReturns the cache-control header that should be sent back \u2026\nReturns the content-disposition header that should be send \u2026\nReturns the content-disposition header that should be send \u2026\nReturns the content-type header that should be send back \u2026\nReturns the content-type header that should be sent back \u2026\nparse will parse the bytes into a part.\nTODO\nParse a response with multipart body into Multipart.\nParse Content-Disposition for header map\nParse content encoding from header map.\nParse content length from header map.\nParse content md5 from header map.\nParse content range from header map.\nParse content type from header map.\nparse datetime from given timestamp\nparse datetime from given timestamp_millis\nParse dateimt from rfc2822.\nParse dateimt from rfc3339.\nParse etag from header map.\nParse header value to string according to name.\nparse_into_metadata will parse standards http headers into \u2026\nParse last modified from header map.\nParse redirect location from header map\nInsert a part into multipart.\nInsert a part header into part.\npercent_decode_path will do percent decoding for http \u2026\npercent_encode_path will do percent encoding for http \u2026\nInvoke the <code>presign</code> operation on the specified path.\nInvoke the <code>presign</code> operation on the specified path.\nDyn version of <code>Accessor::presign</code>\nPush new future into the end of queue.\nPush new future into the start of queue, this task will be \u2026\nQuery the id by parent_id and name.\nGot the range of the reader returned by this read \u2026\nGet range from option\nGet the range inclusive of this BytesContentRange, return \u2026\nGet the range inclusive of this BytesContentRange, return \u2026\nInvoke the <code>read</code> operation on the specified path, returns a \u2026\nInvoke the <code>read</code> operation on the specified path, returns a \u2026\nDyn version of <code>Accessor::read</code>\nGet the current recursive.\nReturn the number of remaining space to push new futures.\nRemove a cache entry.\nInvoke the <code>rename</code> operation on the specified <code>from</code> path and \u2026\nInvoke the <code>rename</code> operation on the specified <code>from</code> path and \u2026\nDyn version of <code>Accessor::rename</code>\nGet the results from RpBatch.\nFetch the id for the root of the service.\nRoot of backend, will be in format like <code>/path/to/dir/</code>\n<code>Scheme</code> of backend.\nSend a request in async way.\nSet name of this backend.\nSet native capabilities for service.\nSet root for backend.\nSet <code>Scheme</code> for backend.\nGot the size of the reader returned by this read operation.\nGet size of BytesRange.\nGet the size of this BytesContentRange, return <code>None</code> if \u2026\nGet the start_after of list operation.\nInvoke the <code>stat</code> operation on the specified path.\nInvoke the <code>stat</code> operation on the specified path.\nDyn version of <code>Accessor::stat</code>\nStore content length to AtomicU64.\nUtilities for opendal testing.\nRead all data from the stream.\nConvert bytes range into Range header.\nConvert bytes content range into Content-Range header.\nConvert bytes range into rust range.\nReturn request\u2019s uri.\nGet the user defined metadata from the op\nValidate given path is match with given EntryMode.\nSet the version for request in this part.\nGet the version of this delete operation.\nGet version from option\nGet version from option\nConstruct <code>Self</code> with given <code>reqwest::Client</code>\nSet the append mode of op.\nSet the boundary with given string.\nSet the content type of option\nSet the chunk of the option\nSet the chunk of op.\nChange the concurrent of this list operation.\nSet the concurrent of the option\nSet the maximum concurrent write task amount.\nSet the content disposition of option\nSet the content type of option\nAdd response context to error.\nSet the executor of the option\nSet the executor of the option\nSet the gap of the option\nSet the If-Match of the option\nSet the If-Match of the option\nSet the If-None-Match of the option\nSet the If-None-Match of the option\nChange the limit of this list operation.\nEnable the lock for the path cacher.\nChange the metakey of this list operation.\nSets the cache-control header that should be send back by \u2026\nSets the cache-control header that should be sent back by \u2026\nSets the content-disposition header that should be send \u2026\nSets the content-disposition header that should be send \u2026\nSets the content-type header that should be send back by \u2026\nSets the content-type header that should be sent back by \u2026\nSet the range of the reader returned by this read \u2026\nSet the range of the option\nUpdate BytesContentRange with range.\nThe recursive is used to control whether the list \u2026\nSet the size of the reader returned by this read operation.\nUpdate BytesContentRange with size.\nChange the start_after of this list operation.\nSet the user defined metadata of the op\nChange the version of this delete operation.\nSet the version of the option\nSet the version of the option\nInvoke the <code>write</code> operation on the specified path, returns a\nInvoke the <code>write</code> operation on the specified path, returns a\nDyn version of <code>Accessor::write</code>\nProviding Key Value Adapter for OpenDAL.\nProviding Typed Key Value Adapter for OpenDAL.\nKvAdapter is the adapter to underlying kv services.\nBackend of kv service. If the storage service is one \u2026\nMetadata for this key value accessor.\nAppend a key into service\nAppend a key into service\nAppend a key into service in blocking way.\nAppend a key into service in blocking way.\nDelete a key from service in blocking way.\nDelete a key from service in blocking way.\nThe blocking version of get.\nThe blocking version of get.\nScan a key prefix to get all keys that start with this key \u2026\nScan a key prefix to get all keys that start with this key \u2026\nThe blocking version of set.\nThe blocking version of set.\nGet the capabilities.\nDelete a key from service.\nReturns the argument unchanged.\nReturns the argument unchanged.\nGet a key from service.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nReturn the metadata of this key value accessor.\nGet the name.\nCreate a new KeyValueAccessorInfo.\nCreate a new kv backend.\nScan a key prefix to get all keys that start with this key.\nScan a key prefix to get all keys that start with this key.\nGet the scheme.\nSet a key into service.\nConfigure root within this backend.\nAdapter is the typed adapter to underlying kv services.\nThe typed kv backend which implements Accessor for typed \u2026\nCapability is used to describe what operations are \u2026\nInfo for this key value accessor.\nValue is the typed value stored in adapter.\nDelete a value from adapter.\nGet a value from adapter.\nScan a key prefix to get all keys that start with this key \u2026\nScan a key prefix to get all keys that start with this key \u2026\nSet a value into adapter.\nGet the capabilities.\nDelete a value from adapter.\nIf typed_kv operator supports delete natively.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nGet a value from adapter.\nIf typed_kv operator supports get natively.\nGet the scheme and name of current adapter.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nMetadata of this value.\nGet the name.\nCreate a new KeyValueAccessorInfo.\nCreate a new kv backend.\nCreate a new dir of value.\nScan a key prefix to get all keys that start with this key.\nScan a key prefix to get all keys that start with this key.\nIf typed_kv operator supports scan natively.\nGet the scheme.\nSet a value into adapter.\nIf typed_kv operator supports set natively.\nSize returns the in-memory size of Value.\nThe corresponding content of this value.\nConfigure root within this backend.\nAppendWrite is used to implement <code>oio::Write</code> based on append\nAppendWriter will implements <code>oio::Write</code> based on append \u2026\nBlockWrite is used to implement <code>oio::Write</code> based on block \u2026\nBlockWriter will implements <code>oio::Write</code> based on block \u2026\nBlockingList is the blocking version of <code>List</code>.\nBlockingLister is a boxed <code>BlockingList</code>\nRead is the trait that OpenDAL returns to callers.\nBlockingReader is a arc dyn <code>BlockingRead</code>.\nBlockingWrite is the trait that OpenDAL returns to callers.\nBlockingWriter is a type erased <code>BlockingWrite</code>\nEntry is returned by <code>Page</code> or <code>BlockingPage</code> during list \u2026\nFlatLister will walk dir in bottom up way:\nFlexBuf is a buffer that support frozen bytes and reuse \u2026\nToHierarchyLister will convert a flat list to hierarchy by \u2026\nPage trait is used by <code>raw::Accessor</code> to implement <code>list</code> \u2026\nThe boxed version of <code>List</code>\nThe result of <code>MultipartWrite::write_part</code>.\nMultipartWrite is used to implement <code>oio::Write</code> based on \u2026\nMultipartWriter will implements <code>oio::Write</code> based on \u2026\nOneShotWrite is used to implement <code>oio::Write</code> based on one \u2026\nOneShotWrite is used to implement <code>oio::Write</code> based on one \u2026\nPageContext is the context passing between <code>PageList</code>.\nPageList is used to implement <code>oio::List</code> based on API \u2026\nPageLister implements <code>oio::List</code> based on <code>PageList</code>.\nPooledBuf is a buffer pool that designed for reusing \u2026\nPositionWrite is used to implement <code>oio::Write</code> based on \u2026\nPositionWriter will implements <code>oio::Write</code> based on \u2026\nPrefixLister is used to filter entries by prefix.\nQueueBuf is a queue of <code>Buffer</code>.\nRangeWrite is used to implement <code>oio::Write</code> based on range \u2026\nRangeWriter will implements <code>oio::Write</code> based on range \u2026\nRead is the internal trait used by OpenDAL to read data \u2026\nReadDyn is the dyn version of <code>Read</code> make it possible to use \u2026\nReader is a type erased <code>Read</code>.\nWrite is the trait that OpenDAL returns to callers.\nWriter is a type erased <code>Write</code>\nAbort the pending writer.\nabort is used to abort the underlying abort.\nabort_block will cancel the block upload and purge all \u2026\nabort_part will cancel the multipart upload and purge all \u2026\nabort_range will abort the range write by abort all \u2026\nPanics\nAdvance the buffer queue by <code>cnt</code> bytes.\nAppend the data to the end of this object.\nThe checksum of the part.\nCleanup the buffer, reset to the initial state.\nClear the buffer queue.\nClose the writer and make sure all data has been flushed.\nClose the writer and make sure all data has been flushed.\nclose is used to close the underlying file.\nBuild a new <code>Buffer</code> from the queue.\ncomplete_block will complete the block upload to build the \u2026\ncomplete_part will complete the multipart upload to build \u2026\ncomplete_range will complete the range write by uploading \u2026\ndone is used to indicate whether the list operation is \u2026\nentries are used to store entries fetched from underlying \u2026\nThe etag of the part.\nFreeze the buffer no matter it\u2019s full or not.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nGet the frozen buffer.\nGet a <code>BytesMut</code> from the pool.\ninitiate_part will call start a multipart upload and \u2026\nInitiate range the range write, the returning value is the \u2026\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nIs the buffer queue empty.\nTotal bytes size inside the buffer queue.\nGet entry\u2019s mode.\nCreate a new MultipartWriter.\nCreate a new AppendWriter.\nCreate a new one shot writer.\nCreate a new MultipartWriter.\nCreate a new BlockWriter.\nCreate a new PositionWriter.\nCreate a new PageLister.\nCreate a new flat lister\nCreate a new hierarchy lister\nCreate a new flat lister\nInitializes a new <code>FlexBuf</code> with the given capacity.\nCreate a new buffer pool with a given size.\nCreate a new entry by its corresponding underlying storage.\nCreate a new buffer queue.\nFetch a new page of <code>Entry</code>\nFetch a new page of <code>Entry</code>\nnext_page is used to fetch next page of entries from \u2026\nGet the current offset of the append object.\nThe number of the part, starting from 0.\nGet the path of entry.\nPush new <code>Buffer</code> into the queue.\nPut slice into flex buf.\nPut a <code>BytesMut</code> back to the pool.\nRead at the given offset with the given size.\nRead data from the reader at the given offset with the \u2026\nRead all data from the reader.\nRead all data from the reader.\nThe dyn version of <code>Read::read_all</code>\nThe dyn version of <code>Read::read</code>.\nSet mode for entry.\nSet path for entry.\nTake the entire buffer queue and leave <code>self</code> in empty \u2026\ntoken is used by underlying storage services to fetch next \u2026\nCreate a new entry with given value.\nSet the initial capacity of the buffer.\nWrite given bytes into writer.\nWrite whole content at once.\nwrite_all_at is used to write the data to underlying \u2026\nwrite_block will write a block of the data.\nwrite_once is used to write the data to underlying storage \u2026\nwrite_once write all data at once.\nwrite_once is used to write the data to underlying storage \u2026\nwrite_once is used to write the data to underlying storage \u2026\nwrite_part will write a part of the data and returns the \u2026\nwrite_range will write a range of data.\nRead represents a read action with given input buf size.\nReadAction represents a read action.\nReadChecker is used to check the correctness of the read \u2026\nTEST_RUNTIME is the runtime used for running tests.\nWrite represents a write action with given input buf size.\nWriteAction represents a read action.\nWriteAction is used to check the correctness of the write \u2026\nCheck will check the correctness of the read process via \u2026\nCheck will check the correctness of the read process via \u2026\nCheck the correctness of the write process.\nGet the check\u2019s chunks.\nReturn the raw data of this read checker.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nInit a service with given scheme.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCreate a new read checker by given size and range.\nCreate a new WriteChecker with given size.\nCapabilities\nConfig for Aliyun Drive services support.\nAlluxio services support.\nConfig for alluxio services support.\nCapabilities\nConfig for Atomicserver services support\nCapabilities\nAzure Storage Blob services support.\nAzure Data Lake Storage Gen2 Support. As known as <code>abfs</code>, \u2026\nAzure Data Lake Storage Gen2 Support.\nAzure File services support.\nAzure File services support.\nb2 services support.\nConfig for backblaze b2 services support.\ncacache service support.\ncacache service support.\nchainsafe services support.\nConfig for Chainsafe services support.\nCapabilities\nCloudflare KV Service Support.\n<code>compio</code>-based file system support.\ncompio-based file system support.\nTencent-Cloud COS services support.\nTencent-Cloud COS services support.\nCapabilities\nConfig for Cloudflare D1 backend support.\ndashmap backend support.\ndashmap backend support.\nDbfs\u2019s REST API support. This service will visit the \u2026\nDbfs\u2019s REST API support.\nDropbox backend support.\nConfig for Dropbox backend support.\nEtcd services support.\nConfig for Etcd services support.\nCapabilities\nfoundationdb service support. Config for FoundationDB.\nPOSIX file system support.\nconfig for file system\nFTP and FTPS services support.\nConfig for Ftp services support.\nGoogle Cloud Storage services support.\nGoogle Cloud Storage services support.\nGoogleDrive backend support.\nGoogleDrive configuration.\nGitHub Action Cache Services support.\nConfig for GitHub Action Cache Services support.\ngithub contents services support.\nConfig for GitHub services support.\nCapabilities\nConfig for Grid file system support.\nA distributed file system that provides high-throughput \u2026\nHadoop Distributed File System (HDFS\u2122) support.\nA distributed file system that provides high-throughput \u2026\nConfig for HdfsNative services support.\nHTTP Read-only service support like Nginx and Caddy.\nConfig for Http service support.\nHuggingface\u2019s API support. This service will visit the \u2026\nConfiguration for Huggingface service support.\nIcloudDrive service support.\nConfig for icloud services support.\nIPFS file system support based on IPFS HTTP Gateway.\nConfig for IPFS file system support.\nIPFS file system support based on IPFS MFS API.\nConfig for IPFS MFS support.\nKoofr services support.\nConfig for Koofr services support.\nCapabilities\nConfig for Libsql services support.\nMemcached service support.\nConfig for MemCached services support\nIn memory service support. (BTreeMap Based)\nConfig for memory.\nmini-moka backend support.\nConfig for mini-moka support.\nmoka backend support.\nConfig for Moka services support.\nCapabilities\nConfig for Mongodb service support.\nFile system support via <code>monoio</code>.\nConfig for monoiofs services support.\nCapabilities\nConfig for Mysql services support.\nHuawei-Cloud Object Storage Service (OBS) support\nConfig for Huawei-Cloud Object Storage Service (OBS) \u2026\nOneDrive backend support.\nConfig for OneDrive backend support.\nAliyun Object Storage Service (OSS) support\nConfig for Aliyun Object Storage Service (OSS) support.\npCloud services support.\nConfig for Pcloud services support.\npersy service support.\nConfig for persy service support.\nPostgreSQL services support.\nConfig for PostgreSQL services support.\nRedb service support.\nConfig for redb service support.\nRedis services support.\nConfig for Redis services support.\nRocksDB service support.\nConfig for Rocksdb Service.\nAws S3 and compatible services (including minio, \u2026\nConfig for Aws S3 and compatible services (including \u2026\nseafile services support.\nConfig for seafile services support.\nSFTP services support. (only works on unix)\nConfig for Sftp Service support.\nSled services support.\nConfig for Sled services support.\nCapabilities\nConfig for Sqlite support.\nSupabase service support\nConfig for supabase service support.\nCapabilities\nConfig for Surrealdb services support.\nOpenStack Swift\u2019s REST API support. For more information \u2026\nConfig for OpenStack Swift support.\nTiKV backend builder\nConfig for Tikv services support.\nupyun services support.\nConfig for upyun services support.\nVercel Cache backend support.\nConfig for Vercel Cache support.\nVercelBlob services support.\nConfig for VercelBlob services support.\nWebDAV backend support.\nConfig for WebDAV backend support.\nWebHDFS\u2019s REST API support. There two implementations of \u2026\nConfig for WebHDFS support.\nYandexDisk services support.\nConfig for YandexDisk services support.\nSet access_key_id of this backend.\nSet access_key_id of this backend.\nSet access_key_id of this backend.\nAccess key id for obs.\nAccess key id for oss.\naccess_key_id of this backend.\nSet access_key_secret of this backend.\nAccess key secret for oss.\nSet access_token of this backend.\nAccess token is used for temporary access to the Dropbox \u2026\nAccess token is used for temporary access to the \u2026\nset the bearer access token for OneDrive\nset the bearer access token for Vercel\nyandex disk oauth access_token. The valid token will looks \u2026\nThe access_token of this backend.\naccess token for dropbox.\nAccess token for gdrive.\nbearer access token for OneDrive\nThe access token for Vercel.\nyandex disk oauth access_token.\nSet the account ID used to authenticate with CloudFlare.\nSet the account identifier for the cloudflare d1 service.\nThe account ID used to authenticate with CloudFlare. Used \u2026\nSet the account id of cloudflare api.\nSet account_key of this backend.\nSet account_key of this backend.\nSet account_key of this backend.\nThe account key of Azblob service backend.\nAccount key of this backend.\nThe account key for azfile.\nSet account_name of this backend.\nSet account_name of this backend.\nSet account_name of this backend.\nThe account name of Azblob service backend.\nAccount name of this backend.\nThe account name for azfile.\nAllow anonymous requests.\nAllow anonymous will allow opendal to send request without \u2026\nAllow anonymous will allow opendal to send request without \u2026\nAllow opendal to send requests without signing when \u2026\nAllow anonymous for oss.\nAllow anonymous will allow opendal to send request without \u2026\napi_key of this backend.\napi_key of this backend.\nYour Apple id\napple_id of this backend.\napplication_key of this backend.\napplicationKey of this backend.\napplication_key_id of this backend.\nkeyID of this backend.\nSet temp dir for atomic write.\nSet temp dir for atomic write.\nSet temp dir for atomic write.\ntmp dir for atomic write\natomic_write_dir of this backend\natomic_write_dir of this backend\nset the authentication token for libsql service.\nAuthentication token for libsql service.\nSet maximum batch operations of this backend.\nSet maximum batch operations of this backend.\nSet maximum batch operations of this backend.\nThe maximum batch operations of Azblob service backend.\nThe size of max batch operations.\nSet maximum batch operations of this backend.\nSet bucket name of this backend. You can find it in \u2026\nSet bucket of this backend. The param is required.\nset the container\u2019s name\nSet the bucket name of the MongoDB GridFs service to \u2026\nSet bucket of this backend. The param is required.\nSet bucket name of this backend.\nSet bucket name of this backend.\nSet bucket name of this backend.\nbucket of this backend.\nbucket of this backend.\nBucket of this backend.\nbucket name\nThe bucket name of the MongoDB GridFs service to \u2026\nBucket for obs.\nBucket for oss.\nbucket name of this backend.\nThe bucket for supabase service.\nbucket address of this backend.\nSet bucket id of this backend. You can find it in \u2026\nSet bucket_id name of this backend.\nbucket id of this backend.\nbucket_id of this backend.\nBuilds the backend and returns the result of \u2026\nBuilds the backend and returns the result of B2Backend.\nBuilds the backend and returns the result of \u2026\nBuild a DbfsBackend.\nBuilds the backend and returns the result of GithubBackend.\nBuild a HuggingfaceBackend.\nBuilds the backend and returns the result of KoofrBackend.\nBuilds the backend and returns the result of PcloudBackend.\nBuilds the backend and returns the result of \u2026\nBuild a SwiftBackend.\nBuilds the backend and returns the result of UpyunBackend.\nBuilds the backend and returns the result of \u2026\nbuild the backend\nBuilds the backend and returns the result of \u2026\nSet the certificate authority file path.\nSet the certificate authority file path.\ncertificate authority file path\ncertificate authority file path\nSet the certificate file path.\nSet the certificate file path.\ncert path\ncert path\nSet checksum algorithm of this backend. This is necessary \u2026\nChecksum Algorithm to use when sending checksums in HTTP \u2026\nSet the chunk size of the MongoDB GridFs service used to \u2026\nThe chunk size of the MongoDB GridFs service used to break \u2026\nSet client_id of this backend.\nSet the client id for Dropbox.\nSet the client id for GoogleDrive.\nThe client_id of this backend.\nclient_id for dropbox.\nClient id for gdrive.\nSet client_secret of this backend.\nSet the client secret for Dropbox.\nSet the client secret for GoogleDrive.\nThe client_secret of this backend.\nclient_secret for dropbox.\nClient secret for gdrive.\nset the network address of redis cluster service. This \u2026\nnetwork address of the Redis cluster service. Can be \u201c\u2026\nSet the collection name of the MongoDB service to \u2026\ncollection of this backend\nicloud config for web session request\nSet the config path for Foundationdb. If not set, will \u2026\nconfig_path for the backend.\nSet the connection_string of the MongoDB service.\nSet the connection_string of the libsql service.\nSet the connection_string of the MongoDB service.\nSet the connection_string of the mysql service.\nSet the connection url string of the postgresql service.\nSet the connection_string of the sqlite service.\nSet the connection_string of the surrealdb service.\nThe connection string of the MongoDB service.\nConnection string for libsql service.\nconnection string of this backend\nThis connection string is used to connect to the mysql \u2026\nThe URL should be with a scheme of either <code>postgres://</code> or \u2026\nSet the connection_string of the sqlite service.\nThe connection string for surrealdb.\nSet container name of this backend.\nSet container of this backend.\nThe container name of Azblob service backend.\nThe container for Swift.\nset the base64 hashed credentials string used for OAuth2 \u2026\nCredentials string for GCS service OAuth2 authentication.\nset the local path to credentials file which is used for \u2026\nLocal path to credentials file for GCS service OAuth2 \u2026\nAdding a customized credential load for service.\nSpecify the customized token loader used by this service.\nSet the database name of the MongoDB GridFs service to \u2026\nSet the database name of the MongoDB service to read/write.\nSet the database of the surrealdb service for read/write.\nThe database name of the MongoDB GridFs service to \u2026\ndatabase of this backend\nThe database for surrealdb.\nSet the database identifier for the cloudflare d1 service.\nSet the database id of cloudflare api.\nSet the path to the cacache data directory. Will create if \u2026\nSet the path to the redb data directory. Will create if \u2026\nSet the path to the rocksdb data directory. Will create if \u2026\nSet the path to the sled data directory. Will create if \u2026\nThat path to the cacache data directory.\npath to the redb data directory.\nThe path to the rocksdb data directory.\nThat path to the sled data directory.\nSet the path to the persy data directory. Will create if \u2026\nThat path to the persy data file. The directory in the \u2026\nset the db used in redis\nthe number of DBs redis can take is unlimited\nSet the default storage class for GCS.\nSet default storage_class for this backend.\nThe default storage class used by gcs.\ndefault storage_class for this backend.\nSet the default ttl for memcached services.\nSet the default ttl for redis services.\nThe default ttl for put operations.\nThe default ttl for put operations.\nSet the delegation token of this backend, used for \u2026\nDelegation token for webhdfs.\nDetect region of S3 bucket.\nDisable config load so that opendal will not load config \u2026\nDisable loading configuration from the environment.\nDisable config load so that opendal will not load config \u2026\nDisable config load so that opendal will not load config \u2026\nDisable loading configuration from the environment.\nDisable config load so that opendal will not load config \u2026\nWebDAV Service doesn\u2019t support copy.\nDisable load credential from ec2 metadata.\nDisable load credential from ec2 metadata.\nDisable batch listing\nDisable batch listing\nDisable stat with override so that opendal will not send \u2026\nDisable stat with override so that opendal will not send \u2026\nDisable attempting to load credentials from the GCE \u2026\nDisable attempting to load credentials from the GCE \u2026\nSet drive_type of this backend.\nThe drive_type of this backend.\nds_web_auth_token must be set in Session\nds_web_auth_token must be set in Session\nemail.\nKoofr email.\nEnable append capacity of this backend.\nEnable append capacity of this backend.\nenable the append capacity\nenable the append capacity\nset enable_copy for sftp backend. It requires the server \u2026\nenable_copy of this backend\nEnable virtual host style so that opendal will send API \u2026\nEnable virtual host style so that opendal will send API \u2026\nSet encryption_algorithm of this backend.\nThe encryption algorithm of Azblob service backend.\nSet encryption_key of this backend.\nThe encryption key of Azblob service backend.\nSet encryption_key_sha256 of this backend.\nThe encryption key sha256 of Azblob service backend.\nendpoint of this backend.\nSet the server address for Atomicserver.\nSet endpoint of this backend\nSet endpoint of this backend.\nSet endpoint of this backend.\nSet endpoint of this backend.\nSet endpoint of this backend.\nset endpoint for ftp backend.\nset the endpoint GCS service uses\nSet the endpoint for ghac service.\nSet endpoint for http backend.\nSet endpoint if ipfs backend.\nSet endpoint for ipfs.\nendpoint.\nset the network address of memcached service.\nSet endpoint of this backend.\nSet endpoint of this backend.\nPcloud endpoint. https://api.pcloud.com for United States \u2026\nset the network address of redis service.\nSet endpoint of this backend.\nendpoint of this backend.\nset endpoint for sftp backend. The format is same as \u2026\nSet endpoint of this backend.\nSet the remote address of this backend\nSet endpoint for http backend.\nSet the remote address of this backend default to \u2026\nendpoint of this backend.\nendpoint of this backend\nThe endpoint of Azblob service backend.\nEndpoint of this backend.\nThe endpoint for azfile.\nEndpoint of this backend.\nThe endpoint for dbfs.\nendpoint of this backend\nendpoint URI of GCS service, default is \u2026\nThe endpoint for ghac service.\nendpoint of this backend\nIPFS gateway endpoint.\nEndpoint for ipfs.\nKoofr endpoint.\nnetwork address of the memcached service.\nEndpoint for obs.\nEndpoint for oss.\npCloud  endpoint address.\nnetwork address of the Redis service. Can be \u201c\u2026\nendpoint of this backend.\nendpoint address of this backend.\nendpoint of this backend\nThe endpoint for supabase service.\nThe endpoint for Swift.\nendpoint of this backend\nEndpoint for webhdfs.\nset the network address of etcd service.\nSet the network address of the TiKV service.\nnetwork address of the Etcd services. If use https, must \u2026\nnetwork address of the TiKV service.\nSet external_id for this backend.\nexternal_id for this backend.\nSet filesystem name of this backend.\nFilesystem name of this backend.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nReturns the argument unchanged.\nfrom_connection_string will make a builder from connection \u2026\nSpecify the http client that used by this service.\nSpecify the http client that used by this service.\nSpecify the http client that used by this service.\nSpecify the http client that used by this service.\nSpecify the http client that used by this service.\nSpecify the http client that used by this service.\nSpecify the http client that used by this service.\nSpecify the http client that used by this service.\nSpecify the http client that used by this service.\nSpecify the http client that used by this service.\nSpecify the http client that used by this service.\nSpecify the http client that used by this service.\nSpecify the http client that used by this service.\nSpecify the http client that used by this service.\nSpecify the http client that used by this service.\nSpecify the http client that used by this service.\nSpecify the http client that used by this service.\nSpecify the http client that used by this service.\nSpecify the http client that used by this service.\nSpecify the http client that used by this service.\nSpecify the http client that used by this service.\nSpecify the http client that used by this service.\nSpecify the http client that used by this service.\nSpecify the http client that used by this service.\nSpecify the http client that used by this service.\nSpecify the http client that used by this service.\nSpecify the http client that used by this service.\nSpecify the http client that used by this service.\nSpecify the http client that used by this service.\nSpecify the http client that used by this service.\nSpecify the http client that used by this service.\nSet the name of the persy index. Will create if not exists.\nThat name of the persy index.\nSet the insecure connection to TiKV.\nwhether using insecure connection to TiKV\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nCalls <code>U::from(self)</code>.\nSet if your apple id in China mainland.\nenable the china origin China region <code>origin</code> Header needs \u2026\nSet kerberos_ticket_cache_path of this backend\nkerberos_ticket_cache_path of this backend\nset key path for sftp backend.\nSet the authorization key for this backend Do not set this \u2026\nkey of this backend\nThe key for supabase service.\nSet the key field name of the d1 service to read/write.\nSet the key field name of the libsql service to read/write.\nSet the key field name of the MongoDB service to \u2026\nSet the key field name of the mysql service to read/write.\nSet the key field name of the postgresql service to \u2026\nSet the key field name of the sqlite service to read/write.\nSet the key field name of the surrealdb service for \u2026\nSet the key field of D1 Database.\nKey field name for libsql service.\nkey field of this backend\nThe key field name for mysql.\nthe key field of postgresql\nSet the key field name of the sqlite service to read/write.\nThe key field for surrealdb.\nSet the key file path.\nSet the key file path.\nkey path\nkey path\nset known_hosts strategy for sftp backend. available \u2026\nknown_hosts_strategy of this backend\nSets the max capacity of the cache.\nSets the max capacity of the cache.\nSets the max capacity of the cache.\nSets the max capacity of the cache.\nName for this cache instance.\nName for this cache instance.\nSet name_node of this backend.\nname node of this backend\nSet the namespace of the surrealdb service for read/write.\nThe namespace for surrealdb.\nSet the namespace ID.\nThe namespace ID. Used as URI path parameter.\nSets the segments number of the cache.\nSet oidc_provider_arn for this backend.\n<code>oidc_provider_arn</code> will be loaded from\nSet oidc_token_file for this backend.\n<code>oidc_token_file</code> will be loaded from\noperator of this backend.\nusername of this backend.\nSet Github repo owner.\nGitHub repo owner.\nSet the parent resource id (url) that Atomicserver uses to \u2026\nparent_resource_id of this backend\nset the password for etcd\nset password for ftp backend.\nset password for http backend\nYour Apple id password\nKoofr application password.\nset the password.\nPcloud password.\nset the password for redis\npassword of this backend.\nSet the password of the surrealdb service for signin.\npassword of this backend.\nset the password for Webdav\nthe password for authentication\npassword of this backend\npassword of this backend\npassword of this backend.\npassword of this backend. (Must be the application \u2026\nMemcached password, optional.\npCloud password.\nthe password for authentication\npassword of this backend.\nThe password for surrealdb.\npassword of this backend.\npassword of this backend\nSet the predefined acl for GCS.\nThe predefined acl for GCS.\nSet an endpoint for generating presigned urls.\nPresign endpoint for oss.\nSet the private key for agent used for Atomicserver.\nprivate_key of this backend\nSet the public key for agent used for Atomicserver. For \u2026\npublic_key of this backend\nSet refresh_token of this backend.\nRefresh token is used for long term access to the Dropbox \u2026\nRefresh token is used for long term access to the \u2026\nThe refresh_token of this backend.\nrefresh_token for dropbox.\nRefresh token for gdrive.\nRegion represent the signing region of this endpoint. This \u2026\nRegion represent the signing region of this endpoint. This \u2026\nSet Github repo name.\nGitHub repo name.\nSet repo id of this backend. This is required.\nRepo id of this backend.\nSet repo name of this backend.\nrepo_name of this backend.\nSet repo type of this backend. Default is model.\nRepo type of this backend. Default is model.\nSet revision of this backend. Default is main.\nRevision of this backend.\nSet role_arn for this backend.\nSet role_arn for this backend.\nIf <code>role_arn</code> is set, we will use already known config as \u2026\nrole_arn for this backend.\nSet role_session_name for this backend.\nSet role_session_name for this backend.\nrole_session_name for this backend.\nrole_session_name for this backend.\nSet the root of this backend.\nSet root of this backend.\nSet the root for Atomicserver.\nSet root of this backend.\nSet root of this backend.\nSet root of this backend.\nSet root of this backend.\nSet root of this backend.\nSet the root within this backend.\nSet root for Compfs\nSet root of this backend.\nset the working directory, all operations will be \u2026\nSet the root for dashmap.\nSet root of this backend.\nSet the root directory for dropbox.\nset the working directory, all operations will be \u2026\nSet the root for Foundationdb.\nSet root for backend.\nset root path for ftp backend.\nset the working directory root of backend\nSet root path of GoogleDrive folder.\nset the working directory root of backend\nSet root of this backend.\nSet the working directory, all operations will be \u2026\nSet root of this backend.\nSet root of this backend.\nSet root path of http backend.\nSet root of this backend.\nSet root of this backend.\nSet root of ipfs backend.\nSet root for ipfs.\nSet root of this backend.\nset the working directory, all operations will be \u2026\nset the working directory, all operations will be \u2026\nSet the root for BTreeMap.\nSet root path of this backend\nSet root path of this backend\nSet the working directory, all operations will be \u2026\nSet root of this backend.\nset the working directory, all operations will be \u2026\nSet root of this backend.\nSet root path of OneDrive folder.\nSet root of this backend.\nSet root of this backend.\nSet the working directory, all operations will be \u2026\nSet the root for Redb.\nset the working directory, all operations will be \u2026\nset the working directory, all operations will be \u2026\nSet root of this backend.\nSet root of this backend.\nset root path for sftp backend. It uses the default \u2026\nSet the root for sled.\nset the working directory, all operations will be \u2026\nSet root of this backend.\nset the working directory, all operations will be \u2026\nSet root of this backend.\nSet root of this backend.\nSet root of this backend.\nSet root path of http backend.\nSet the working directory of this backend\nSet root of this backend.\nThe Root of this backend.\nroot of this backend.\nwork dir of this backend\nThe root of Azblob service backend.\nRoot of this backend.\nThe root path for azfile.\nroot of this backend.\nroot of this backend.\nRoot within this backend.\nroot of this backend.\nRoot of this backend.\nSet the working directory of OpenDAL.\nThe root path for dashmap.\nThe root for dbfs.\nroot path for dropbox.\nthe working directory of the etcd service. Can be \u201c\u2026\nroot of the backend.\nroot dir for backend\nroot of this backend\nroot URI, all operations happens under <code>root</code>\nThe root for gdrive\nThe root path for ghac.\nroot of this backend.\nThe working directory, all operations will be performed \u2026\nwork dir of this backend\nwork dir of this backend\nroot of this backend\nRoot of this backend. Can be \u201c/path/to/dir\u201d.\nroot of this backend.\nIPFS root.\nRoot for ipfs.\nroot of this backend.\nRoot for libsql service.\nthe working directory of the service. Can be \u201c\u2026\nroot of the backend.\nroot path of this backend\nroot path of this backend\nroot of this backend\nThe Root of this backend.\nThe root for mysql.\nRoot for obs.\nroot path of OneDrive folder.\nRoot for oss.\nroot of this backend.\nRoot of this backend.\nThe root for redb.\nthe working directory of the Redis service. Can be \u201c\u2026\nthe working directory of the service. Can be \u201c\u2026\nroot of this backend.\nroot of this backend.\nroot of this backend\nThe root for sled.\nset the working directory, all operations will be \u2026\nThe root for supabase service.\nThe root for surrealdb.\nThe root for Swift.\nroot of this backend.\nroot of this backend.\nroot of this backend\nRoot for webhdfs.\nroot of this backend.\nSet the runtime token for ghac service.\nThe runtime token for ghac service.\nSet sas_token of this backend.\nThe sas token of Azblob service backend.\nThe sas token for azfile.\nset the GCS service scope\nScope for gcs.\nSet secret_access_key of this backend.\nSet secret_access_key of this backend.\nSecret access key for obs.\nsecret_access_key of this backend.\nSet secret_id of this backend.\nSecret ID of this backend.\nSet secret_key of this backend.\nSecret key of this backend.\nSet temporary credential used in AWS S3 connections\nSet the name of the persy segment. Will create if not \u2026\nThat name of the persy segment.\nSets the segments number of the cache.\nSet server_side_encryption for this backend.\nSet server_side_encryption for this backend.\nServer side encryption for oss.\nserver_side_encryption for this backend.\nSet server_side_encryption_aws_kms_key_id for this backend\nserver_side_encryption_aws_kms_key_id for this backend\nSet server_side_encryption_customer_algorithm for this \u2026\nserver_side_encryption_customer_algorithm for this backend.\nSet server_side_encryption_customer_key for this backend.\nserver_side_encryption_customer_key for this backend.\nSet server_side_encryption_customer_key_md5 for this \u2026\nSet server_side_encryption_customer_key_md5 for this \u2026\nSet server_side_encryption_key_id for this backend.\nServer side encryption key id for oss.\nEnable server side encryption with aws managed kms key\nEnable server side encryption with customer key.\nEnable server side encryption with customer key.\nEnable server side encryption with customer managed kms key\nEnable server side encryption with s3 managed key\nSet the GCS service account.\nService Account for gcs.\nSet temporary credential used in AWS S3 connections\nsession_token (aka, security token) of this backend.\nSet file share name of this backend.\nThe share name for azfile.\nSet sts_endpoint for this backend.\n<code>sts_endpoint</code> will be loaded from\nSet the table name of the d1 service to read/write.\nSet the table name of the libsql service to read/write.\nSet the table name of the mysql service to read/write.\nSet the table name of the postgresql service to read/write.\nSet the table name for Redb.\nSet the table name of the sqlite service to read/write.\nSet the table name of the surrealdb service for read/write.\nSet the table of D1 Database.\nTable name for libsql service.\nThe table name for mysql.\nthe table of postgresql\nThe table name for redb.\nSet the table name of the sqlite service to read/write.\nThe table for surrealdb.\nSets the time to idle of the cache.\nSets the time to idle of the cache.\nSets the time to idle of the cache.\nSets the time to idle of the cache.\nSets the time to live of the cache.\nSets the time to live of the cache.\nSets the time to live of the cache.\nSets the time to live of the cache.\nSet the token used to authenticate with CloudFlare.\nSet api token for the cloudflare d1 service.\nSet the token of this backend.\nProvide the OAuth2 token to use.\nGithub access_token.\nset bearer token for http backend\nSet the token of this backend.\nSet the token of this backend.\nVercel Blob token.\nset the bearer token for Webdav\nThe token used to authenticate with CloudFlare.\nSet the token of cloudflare api.\nThe token for dbfs.\nA Google Cloud OAuth2 token.\nGitHub access_token.\ntoken of this backend\nToken of this backend.\nThe token for Swift.\nvercel blob token.\ntoken of this backend\nSet the tree for sled.\nThe tree for sled.\nTrust token and ds_web_auth_token is used for temporary \u2026\nSession\nSet url of this backend.\nurl of this backend\nset user for ftp backend.\nSet user of this backend\nset user for sftp backend.\nuser of this backend\nuser of this backend\nuser of this backend\nset the username for etcd\nset username for http backend\nset the username.\nPcloud username.\nset the username for redis\nusername of this backend.\nSet the username of the surrealdb service for signin.\nset the username for Webdav\nthe username to connect etcd service.\nusername of this backend\nMemcached username, optional.\npCloud username.\nthe username to connect redis service.\nusername of this backend.\nThe username for surrealdb.\nusername of this backend\nSet the value field name of the d1 service to read/write.\nSet the value field name of the libsql service to \u2026\nSet the value field name of the MongoDB service to \u2026\nSet the value field name of the mysql service to \u2026\nSet the value field name of the postgresql service to \u2026\nSet the value field name of the sqlite service to \u2026\nSet the value field name of the surrealdb service for \u2026\nSet the value field of D1 Database.\nValue field name for libsql service.\nvalue field of this backend\nThe value field name for mysql.\nthe value field of postgresql\nSet the value field name of the sqlite service to \u2026\nThe value field for surrealdb.\nset the version that used by cache.\nThe version that used by cache.");